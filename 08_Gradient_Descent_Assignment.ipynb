{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<h1 style=“font-size:30px;“>Gradient Descent Assignment</h1>\n",
    "\n",
    "The previous section on Gradient Descent focused on how to implement the gradient calculation and weight update for a single variable ( `m` ), using simple math operations. In this assignment, you do the same, but for 2 variables.  \n",
    "\n",
    "We will use the full form of a line i.e. `y = mx + c`.  \n",
    "You need to estimate the values of two variables `m` and `c`, using Stochastic Gradient Descent.\n",
    "\n",
    "\n",
    "Tasks to implement for the 2 variables:   \n",
    "1. Implement the gradient calculation step for the 2 variables.\n",
    "2. Implement the weight update step for the 2 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Maximum Points: 30\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Section</h3></td> <td><h3>Problem</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>2.1</h3></td> <td><h3>Implement Gradients </h3></td> <td><h3>20</h3></td> </tr>\n",
    "        <tr><td><h3>2.2</h3></td> <td><h3>Implement SGD</h3></td> <td><h3>10</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:24.438409Z",
     "start_time": "2021-12-22T09:18:18.521229Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For reproducibility\n",
    "tf.random.set_seed(41)\n",
    "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 1 Generate Sample Data\n",
    "\n",
    "Here we define a function that will generate some sample data based on a **linear model** in the presence of random noise. We will generate 1,000 data points for this experiment. The independent variable, `x`, has values randomly distributed between -5 to 5. Values for `m` and `c` have been specified to create the data points for the dependent variable (`y`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:27.930244Z",
     "start_time": "2021-12-22T09:18:24.441410Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Generating y = mx + c + random noise.\n",
    "num_data = 1000\n",
    "\n",
    "# True values of m and c\n",
    "m_line = 3.3\n",
    "c_line = 5.3\n",
    "\n",
    "\n",
    "# Input (Generate random data between [-5,5]).\n",
    "x = tf.random.uniform([num_data], minval=-5, maxval=5)\n",
    "\n",
    "# Output (Generate data assuming y = mx + c + noise).\n",
    "y_label = m_line * x + c_line + tf.random.normal(x.shape).numpy()\n",
    "y = m_line * x + c_line\n",
    "\n",
    "# Plot the generated data points. \n",
    "plt.plot(x, y_label, '.', color='g', label=\"Data points\")\n",
    "plt.plot(x, y, color='b', label='y = mx + c', linewidth=3)\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The goal is to find the \"unknown\" parameters ($m$ and $c$) of the linear model below so that we can predict $y$, given some value of $x$.  \n",
    "\n",
    "$$ y = mx + c $$  \n",
    "\n",
    "We have a set of data points $(x_i, y_i)$, and they should all satisfy the equation above. i.e.,\n",
    "\n",
    "$$ y_i = m x_i + c $$  \n",
    "\n",
    "Since the data is not perfectly linear due to the added noise, we can represent the **error** or a **residual** as follows: \n",
    "\n",
    "$$ e_i = (y_i - m x_i -c) $$   \n",
    "\n",
    "\n",
    "Next, we need to find a value of $m$ and $c$ that minimizes the error above. Positive or negative values of error are equally bad. So, we need to minimize the square of the above error, across all the data points.\n",
    "\n",
    "$$ l_{sse} = \\sum^N_{i=1}(y_i - m x_i -c)^2 \\\\ $$\n",
    "\n",
    "\n",
    "This form of the **loss function** is the sum of squared errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 2 Gradient Descent [30 Points]\n",
    "\n",
    "\n",
    "We have already seen how the Math works for `m`. The same approach is used in the case of `m` and `c`.    \n",
    "We calculate the loss function and then take partial derivatives w.r.t `m` and `c` respectively. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "l &= \\sum^n_{i=1}(y_i - m x_i - c)^2 \\\\\n",
    "\\frac{\\partial l}{\\partial m}  &= -2 \\sum^n_{i=1} x_i(y_i - m x_i - c) \\\\\n",
    "\\frac{\\partial l}{\\partial c}  &= -2 \\sum^n_{i=1} (y_i - m x_i - c) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To follow the slope of the curve, we move `m` in the direction of negative gradient. However, we must control the rate at which we go down the slope, so that we do not overshoot the minimum. Thus, we use a parameter $\\lambda$ called the `learning rate`.\n",
    "$$\n",
    "\\begin{align}\n",
    "m_k &= m_{k-1} - \\lambda \\frac{\\partial l}{\\partial m} \\\\\n",
    "c_k &= c_{k-1} - \\lambda \\frac{\\partial l}{\\partial c} \\\\ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "That is it! \n",
    "\n",
    "Let's implement this in code to see that it really works. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<!-- <div class=\"alert alert-block alert-info\">\n",
    "    <b>1. Implement Gradients: 20 Points</b>\n",
    "</div> -->\n",
    "\n",
    "### 2.1 Implement Gradients [20 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Useful tensorflow methods for this functions:**\n",
    "\n",
    "1. [reduce_sum](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum)\n",
    "2. [gather](https://www.tensorflow.org/api_docs/python/tf/gather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "block_plot = False\n",
    "def plotting_1d(x, label):\n",
    "# Now plotting \n",
    "    plt.figure\n",
    "    plt.xlabel(label)\n",
    "    plt.plot(x.numpy(),'c--')\n",
    "    plt.title('Generic 1D plot')\n",
    "    plt.show(block=block_plot)\n",
    "\n",
    "def plotting_2d(x, x_axis_label, y, y_axis_label):\n",
    "    plt.figure\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    plt.plot(x.numpy(),y.numpy(),'c--')\n",
    "    plt.show(block=block_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:27.946247Z",
     "start_time": "2021-12-22T09:18:27.934239Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_wrt_m_and_c(inputs, labels, m, c, k):\n",
    "    \n",
    "    '''\n",
    "    All arguments are defined in the training section of this notebook. \n",
    "    This function will be called from the training section.  \n",
    "    So before completing this function go through the whole notebook.\n",
    "    \n",
    "    inputs (torch.tensor): input (X)\n",
    "    labels (torch.tensor): label (Y)\n",
    "    m (float): slope of the line\n",
    "    c (float): vertical intercept of line\n",
    "    k (torch.tensor, dtype=int): random index of data points\n",
    "    '''\n",
    "    num_iter0 = 970\n",
    "    lr0 = 0.005\n",
    "\n",
    "    # Data structures needed for computations\n",
    "    loss = tf.Variable(tf.zeros(shape=[num_iter0]))\n",
    "\n",
    "    # gradient w.r.t to m is g_m \n",
    "    # gradient w.r.t to c is g_c\n",
    "    \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    # Start computing loss\n",
    "    '''\n",
    "    The below code is not correct, there is a much simpler way to do this using the tf framework.\n",
    "    for i in range(0, num_iter0):\n",
    "        pde_loss_m = -2 * tf.reduce_sum(inputs * (labels - m * inputs - c))/len(inputs)\n",
    "        pde_loss_c = -2 * tf.reduce_sum(labels - m * inputs - c)/len(inputs)\n",
    "        \n",
    "        # New slope and bias\n",
    "        m = m - lr0 * pde_loss_m\n",
    "        c = c - lr0 * pde_loss_c\n",
    "        \n",
    "        # Compute error\n",
    "        e = labels - m * inputs - c\n",
    " \n",
    "        \n",
    "        # Loss function based on the error\n",
    "        loss[i].assign(tf.reduce_sum(tf.multiply(e,e))/len(inputs))\n",
    "        print(i,loss[i].numpy())\n",
    "    \n",
    "    g_m = m.numpy()\n",
    "    c_m = c.numpy()\n",
    "    '''\n",
    "    g_c = -2.0 * tf.math.reduce_sum(tf.gather(labels,k) - m * tf.gather(inputs,k) - c)\n",
    "    g_m = -2.0 * tf.math.reduce_sum(tf.gather(inputs,k) * (tf.gather(labels,k) - m * tf.gather(inputs,k) - c))\n",
    "    return g_m, g_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test your code before submitting it using the below code cell.**\n",
    "\n",
    "For the given input:\n",
    "```\n",
    "X = tf.convert_to_tensor([-0.0374,  2.6822, -4.1152])\n",
    "Y = tf.convert_to_tensor.tensor([ 5.1765, 14.1513, -8.2802])\n",
    "m = 2\n",
    "c = 3\n",
    "k = tf.convert_to_tensor.tensor([0, 2])\n",
    "```\n",
    "Output:\n",
    "```\n",
    "Gradient of m : -24.93\n",
    "Gradient of c : 1.60\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:27.993237Z",
     "start_time": "2021-12-22T09:18:27.953242Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of m : -24.93\n",
      "Gradient of c : 1.60\n"
     ]
    }
   ],
   "source": [
    "X = tf.convert_to_tensor([-0.0374,  2.6822, -4.1152])\n",
    "Y = tf.convert_to_tensor([ 5.1765, 14.1513, -8.2802])\n",
    "m = 2\n",
    "c = 3\n",
    "k = tf.convert_to_tensor([0, 2])\n",
    "\n",
    "gm, gc = gradient_wrt_m_and_c(X, Y, m, c, k)\n",
    "\n",
    "print(f'Gradient of m : {gm:.2f}')\n",
    "print(f'Gradient of c : {gc:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.103247Z",
     "start_time": "2021-12-22T09:18:27.997254Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Implement gradients wrt m",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.134255Z",
     "start_time": "2021-12-22T09:18:28.106241Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Implement gradients wrt c",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Stochastic Gradient Descent (SGD) [10 point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.150242Z",
     "start_time": "2021-12-22T09:18:28.137241Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_m_and_c(m, c, g_m, g_c, lr):\n",
    "    '''\n",
    "    All arguments are defined in the training section of this notebook. \n",
    "    This function will be called from the training section.  \n",
    "    So before completing this function go through the whole notebook.\n",
    "    \n",
    "    g_m = gradient w.r.t to m\n",
    "    c_m = gradient w.r.t to c\n",
    "    '''\n",
    "    # Update m and c parameters.\n",
    "    # store updated value of m is updated_m variable\n",
    "    # store updated value of c is updated_c variable\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    updated_m = m - lr * g_m\n",
    "    updated_c = c - lr * g_c\n",
    "    return updated_m, updated_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Test your code before submitting it using the below code cell.**\n",
    "\n",
    "For the given input:\n",
    "```\n",
    "m = 2\n",
    "c = 3\n",
    "g_m = -24.93\n",
    "g_c = 1.60\n",
    "lr = 0.001\n",
    "```\n",
    "Output:\n",
    "```\n",
    "Updated m: 2.02\n",
    "Updated c: 3.00\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.166242Z",
     "start_time": "2021-12-22T09:18:28.154245Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated m: 2.02\n",
      "Updated c: 3.00\n"
     ]
    }
   ],
   "source": [
    "m = 2\n",
    "c = 3\n",
    "g_m = -24.93\n",
    "g_c = 1.60\n",
    "lr = 0.001\n",
    "m, c = update_m_and_c(m, c, g_m, g_c, lr)\n",
    "\n",
    "print('Updated m: {0:.2f}'.format(m))\n",
    "print('Updated c: {0:.2f}'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.182241Z",
     "start_time": "2021-12-22T09:18:28.170242Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "SGD update of m",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:28.198245Z",
     "start_time": "2021-12-22T09:18:28.186239Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "SGD update of c",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## 3  Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:35.423454Z",
     "start_time": "2021-12-22T09:18:28.203243Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent with Minibatch.\n",
    "\n",
    "# Input \n",
    "X = x\n",
    "\n",
    "# output label.\n",
    "Y = y_label\n",
    "\n",
    "num_iter = 1000\n",
    "batch_size = 10\n",
    "\n",
    "# display updated values after every 50 iterations.\n",
    "display_count = 50\n",
    "# \n",
    "\n",
    "lr = 0.001\n",
    "m = 2\n",
    "c = 1\n",
    "print()\n",
    "loss = []\n",
    "\n",
    "for i in range(0, num_iter):\n",
    "\n",
    "    # Randomly select a training data point.\n",
    "    k = tf.random.uniform(shape=[batch_size], minval=0, maxval=len(Y)-1, dtype=tf.int32)\n",
    "\n",
    "    # Calculate gradient of m and c using a mini-batch.\n",
    "    g_m, g_c = gradient_wrt_m_and_c(X, Y, m, c, k)\n",
    "    \n",
    "    # update m and c parameters.\n",
    "    m, c = update_m_and_c(m, c, g_m, g_c, lr)\n",
    "    \n",
    "    # Calculate Error.\n",
    "    e = Y - m * X - c\n",
    "    \n",
    "    # Compute Loss Function.\n",
    "    current_loss = tf.math.reduce_sum(tf.math.multiply(e,e))\n",
    "    loss.append(current_loss)\n",
    "\n",
    "    if i % display_count==0:\n",
    "        print('Iteration: {}, Loss: {}, updated m: {:.3f}, updated c: {:.3f}'.format(i, loss[i], m, c))\n",
    "        y_pred = m * X + c\n",
    "        # Plot the line corresponding to the learned m and c.\n",
    "        plt.plot(x, y_label, '.', color='g')\n",
    "        plt.plot(x, y, color='b', label='Line corresponding to m={0:.2f}, c={1:.2f}'.\n",
    "                 format(m_line, c_line), linewidth=3)\n",
    "        plt.plot(X, y_pred, color='r', label='Line corresponding to m_learned={0:.2f}, c_learned={1:.2f}'.\n",
    "                 format(m, c), linewidth=3)\n",
    "        plt.title(\"Iteration : {}\".format(i))\n",
    "        plt.legend()\n",
    "\n",
    "        plt.ylabel('y')\n",
    "        plt.xlabel('x')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:35.755447Z",
     "start_time": "2021-12-22T09:18:35.425454Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Loss of after last batch: {}'.format(loss[-1]))\n",
    "print('Leaned \"m\" value: {}'.format( m))\n",
    "print('Leaned \"c\" value: {}'.format( c))\n",
    "\n",
    "# Plot loss vs m.\n",
    "plt.figure\n",
    "plt.plot(range(len(loss)),loss)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:35.771450Z",
     "start_time": "2021-12-22T09:18:35.757449Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "lines_to_next_cell": 0,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the predicted y values using the learned m and c.\n",
    "y_pred = m * X + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T09:18:36.007447Z",
     "start_time": "2021-12-22T09:18:35.774452Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the line corresponding to the learned m and c\n",
    "plt.plot(x, y_label, '.', color='g', label='X and Y')\n",
    "plt.plot(x, y, color='b', label='Line corresponding to m={0:.2f}, c={1:.2f}'.format(m_line, c_line), linewidth=3)\n",
    "plt.plot(X, y_pred, color='r', label='Line corresponding to m_learned={0:.2f}, c_learned={1:.2f}'.format(m, c), linewidth=3)\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": [],
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": [],
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
