{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNS1xQOYHo0Wx5ZtggihzDs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sateesh12/tf/blob/main/vgg16_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFBtwW3WcE5s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import zipfile\n",
        "import requests\n",
        "import glob as glob\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
        "from dataclasses import dataclass\n",
        "\n",
        "block_plot = False\n",
        "plt.rcParams['figure.figsize'] = (12,9)\n",
        "SEED_VALUE = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_unzip(url, save_name):\n",
        "    #url = url\n",
        "    file = requests.get(url)\n",
        "    open(save_name, 'wb').write(file.content)\n",
        "    try:\n",
        "        with zipfile.ZipFile(save_name) as z:\n",
        "            z.extractall(\"./\")\n",
        "            print('Extracted all')\n",
        "    except:\n",
        "        print('Invalid data')\n",
        "\n",
        "download_and_unzip('https://www.dropbox.com/s/6nrjxr2ycnpcy63/dataset_balls.zip?dl=1',\n",
        "    'dataset_balls.zip')"
      ],
      "metadata": {
        "id": "yETkC-uJfdpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import datasets\n",
        "@dataclass (frozen=True)\n",
        "class DatasetConfig:\n",
        "    NUM_CLASSES:  int = 10\n",
        "    IMG_HEIGHT:    int = 224\n",
        "    IMG_WIDTH:     int  = 224\n",
        "    CHANNELS:        int  = 3\n",
        "    BATCH_SIZE:     int  = 32\n",
        "    DATA_ROOT_TRAIN: str='./dataset_balls/train'\n",
        "    DATA_ROOT_VALID: str='./dataset_balls/valid'\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainingConfig:\n",
        "    BATCH_SIZE: int = 32\n",
        "    EPOCSHS:     int = 51\n",
        "    LEARNING_RATE: float = 0.0001\n",
        "    CHECKPOINT_DIR: str = './saved_models_balls'\n"
      ],
      "metadata": {
        "id": "eUm4a4fthFPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an existing VGG16  model using Keras.\n",
        "input_shape = (DatasetConfig.IMG_HEIGHT, DatasetConfig.IMG_WIDTH, DatasetConfig.CHANNELS)\n",
        "print('Load the model with random weights')\n",
        "vgg16_conv_base = tf.keras.applications.vgg16.VGG16(input_shape=input_shape, include_top=False, weights=None)\n",
        "vgg16_conv_base.trainable = True\n",
        "print('All kernel weights are trainable')\n",
        "print(vgg16_conv_base.summary())"
      ],
      "metadata": {
        "id": "rvSjeMpMi_Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add classifictaion layer, the above CNN extracted the features.\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "x = vgg16_conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "outputs = layers.Dense(DatasetConfig.NUM_CLASSES, activation='softmax')(x)\n",
        "vgg16_model = keras.Model(inputs, outputs)\n",
        "print(vgg16_model.summary())"
      ],
      "metadata": {
        "id": "_FmH1M2Y84iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation set\n",
        "train_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_TRAIN,\n",
        "                                                                        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                                                        seed = SEED_VALUE,\n",
        "                                                                        label_mode='categorical',\n",
        "                                                                        image_size = (DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT))\n",
        "valid_dataset = image_dataset_from_directory(directory=DatasetConfig.DATA_ROOT_VALID,\n",
        "                                                                        batch_size=TrainingConfig.BATCH_SIZE,\n",
        "                                                                        seed = SEED_VALUE,\n",
        "                                                                        label_mode='categorical',\n",
        "                                                                        image_size = (DatasetConfig.IMG_WIDTH, DatasetConfig.IMG_HEIGHT))"
      ],
      "metadata": {
        "id": "3jNkgYaCAOVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.engine.training import optimizer\n",
        "# Compile and train the model of vgg-16\n",
        "vgg16_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=TrainingConfig.LEARNING_RATE),\n",
        "                                                       loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                                                       metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=TrainingConfig.CHECKPOINT_DIR,\n",
        "                                                                                                save_weights_only=False,\n",
        "                                                                                                monitor='val_accuracy',\n",
        "                                                                                                mode='max',\n",
        "                                                                                                save_best_only=True)\n",
        "trainig_results = vgg16_model.fit(train_dataset,\n",
        "                                                validation_data=valid_dataset,\n",
        "                                                epochs=TrainingConfig.EPOCSHS,\n",
        "                                                workers=4,\n",
        "                                                use_multiprocessing=True,\n",
        "                                                callbacks=model_checkpoint_callback)"
      ],
      "metadata": {
        "id": "4h3iBEgxBszy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard plotting function, should start to make a module of this !\n",
        "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 4))\n",
        "\n",
        "    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):\n",
        "        metrics = [metrics,]\n",
        "        metric_name = [metric_name,]\n",
        "\n",
        "    for idx, metric in enumerate(metrics):\n",
        "        ax.plot(metric, color=color[idx])\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(ylabel)\n",
        "    plt.xlim([0, TrainingConfig.EPOCSHS-1])\n",
        "    plt.ylim(ylim)\n",
        "    # Tailor x-axis tick marks\n",
        "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
        "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
        "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
        "    plt.grid(True)\n",
        "    plt.legend(metric_name)\n",
        "    plt.show(block=block_plot)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "-1DeoJSXF7HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = trainig_results.history['loss']\n",
        "train_acc  = trainig_results.history['accuracy']\n",
        "valid_loss = trainig_results.history['val_loss']\n",
        "valid_acc  = trainig_results.history['val_accuracy']\n",
        "\n",
        "max_loss = max(max(train_loss), max(valid_loss))\n",
        "plot_results([train_acc, valid_acc], ylabel = 'Accuracy',\n",
        "                ylim=[0.0, 1.0],\n",
        "                metric_name = [\"Training Accuracy\",\" Validation Accuracy\"],\n",
        "                color=[\"g\",\"b\"])\n",
        "\n",
        "plot_results([train_loss, valid_loss], ylabel = 'Loss',\n",
        "                ylim=[0.0, max_loss],\n",
        "                metric_name = [\"Training Loss\", \"Validation Loss\"],\n",
        "                color=[\"g\",\"b\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "_xYI3sc_SyQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}