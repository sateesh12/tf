{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "block_plot = False\n",
    "\n",
    "SEED_VALUE = 42\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "tf.random.set_seed(SEED_VALUE)\n",
    "\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d013f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sys_config():\n",
    "    gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(gpu_devices)\n",
    "\n",
    "    if(len(gpu_devices) > 0):\n",
    "        print('Using GPU')\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "        tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "\n",
    "        os.environ['TF_USE_CUDNN'] = \"true\"\n",
    "    else:\n",
    "        print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061883f-332e-4510-9b2c-12a4e6a0ee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  get_data():\n",
    "    mnist_data = tf.keras.datasets.mnist\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = mnist_data.load_data()\n",
    "    return((X_train, y_train), (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff6fbf-9525-4f61-b146-d932767eaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_set, test_set, resize_to=None, num_classes=10, seed=42):\n",
    "    (X_train, y_train) = train_set\n",
    "    (X_test, y_test)   = test_set\n",
    "\n",
    "    # Split complete training data into vaidation data and training data-set\n",
    "    X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, shuffle=True, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "    # Add an axis to gray scale image, not sure why ?\n",
    "    if len(X_train.shape) != 4:\n",
    "        X_train = tf.expand_dims(X_train, axis=3)\n",
    "        X_validate = tf.expand_dims(X_validate, axis=3)\n",
    "        X_test = tf.expand_dims(X_test, axis=3)\n",
    "\n",
    "    # Re-size if requested via the command line parameters\n",
    "    if resize_to:\n",
    "        if isinstance(resize_to, int):\n",
    "            resize_to = (resize_to, resize_to) \n",
    "        X_train    = tf.image.resize(X_train,    resize_to)\n",
    "        X_validate = tf.image.resize(X_validate, resize_to)\n",
    "        X_test     = tf.image.resize(X_test,     resize_to)\n",
    "\n",
    "    n_train = X_train.shape[0]\n",
    "    n_validate = X_validate.shape[0]\n",
    "    n_test = X_test.shape[0]\n",
    "    image_shape = X_train.shape[0]\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print('There are {} training examples'.format(n_train))\n",
    "    print('There are {} validation examples'.format(n_validate))\n",
    "    print('There are {} test examples'.format(n_test))\n",
    "\n",
    "    assert num_classes == len(np.unique(y_train)), \"Mis-match in number of classes.\"\n",
    "    print('There are {} classes'.format(num_classes))\n",
    "\n",
    "    NUM_CLASSES = num_classes\n",
    "\n",
    "    # One hot encoding of the output classes\n",
    "    if len(y_train.shape) != 2:\n",
    "        y_train    = tf.one_hot(y_train, NUM_CLASSES)\n",
    "        y_validate = tf.one_hot(y_validate, NUM_CLASSES)\n",
    "        y_test     = tf.one_hot(y_test, NUM_CLASSES)\n",
    "\n",
    "    print('\\nData split:\\n')\n",
    "    print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "    print(f'X_validate: {X_validate.shape}, y_validate: {y_validate.shape}')\n",
    "    print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "\n",
    "    # Normalize the data\n",
    "    X_train    = tf.cast(X_train, tf.float32) / 255.0\n",
    "    X_validate = tf.cast(X_validate,tf.float32) / 255.0\n",
    "    X_test     = tf.cast(X_test,tf.float32) / 255.0\n",
    "\n",
    "    print('Ground truth has been one hot encoded')\n",
    "    print(np.transpose(y_train[:9]))\n",
    "\n",
    "    return(X_train, y_train), (X_validate,y_validate), (X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb888628-962a-4ced-892b-736bd3b9af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(X,y):\n",
    "    plt.figure(figsize=(18,8))\n",
    "    for i in range(8):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(X[i], cmap='gray')\n",
    "        plt.xlabel(y[i])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    plt.suptitle('Dataset Samples', fontsize=18)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    plt.show(block=block_plot)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625b454-5d3a-4c72-a95a-3887b3031aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    IMG_HEIGHT: int = 32\n",
    "    IMG_WIDTH:  int = 32\n",
    "    CHANNELS:   int = 1\n",
    "    NUM_CLASSES: int = 10\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE: int = 32\n",
    "    EPOCHS:     int = 21\n",
    "    LEARNING_RATE: float = 0.01\n",
    "    SEED: int = 42\n",
    "\n",
    "data_config = DatasetConfig()\n",
    "training_config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64d8f9-76e2-4462-98fb-564ce1e02213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense, Flatten, Input, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162299dd-8ee7-44f7-a90b-02647008f7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet_model(input_shape=(32,32,1), num_classes=10, print_summary=True):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First CNN Layer\n",
    "    x = Conv2D(6, 5, padding='valid')(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "\n",
    "    # Second CNN layer\n",
    "    x = Conv2D(16, 5, padding='valid')(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    feature_extractor_output = MaxPool2D()(x)\n",
    "\n",
    "    # Flatten to send into an MLP\n",
    "    flattened = Flatten()(feature_extractor_output)\n",
    "\n",
    "    x = Dense(120, activation='relu')(flattened)\n",
    "    x = Dense(84, activation='relu')(x)\n",
    "\n",
    "    headout = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=headout, name='LeNet5')\n",
    "\n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "        \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda35153-829f-4826-b50f-1f6748ba93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_set, print_summary=False):\n",
    "    (X_train, y_train) = train_set\n",
    "\n",
    "    model = LeNet_model(input_shape=(data_config.IMG_HEIGHT, data_config.IMG_WIDTH, data_config.CHANNELS),\n",
    "                        num_classes=data_config.NUM_CLASSES,\n",
    "                        print_summary=True)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=training_config.LEARNING_RATE), \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),metrics=['accuracy'])\n",
    "\n",
    "    results = model.fit(X_train, y_train, epochs=training_config.EPOCHS, batch_size=training_config.BATCH_SIZE,\n",
    "                        validation_data=(X_validate,y_validate))\n",
    "\n",
    "    return model, results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33b188-d148-490e-9877-16090afed2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533339c2-8443-41a9-96fc-4577e77bd2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import(MultipleLocator, FormatStrFormatter)\n",
    "def plot_results(metrics, ylabel=None, ylim=None, metric_name=None, color=None):\n",
    "    fig, ax = plt.subplots(figsize=(15,4))\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(ylabel)\n",
    "    plt.xlim([0, training_config.EPOCHS - 1])\n",
    "    plt.ylim(ylim)\n",
    "    # Tailor x-axis tick marks\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "    plt.grid(True)\n",
    "    plt.show(block=block_plot)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6959994-afb7-4bb9-8962-447f72bc4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, *test_set):\n",
    "    X_test, y_test = test_set\n",
    "    test_results = model.evaluate(X_test, y_test)\n",
    "    random.seed(training_config.SEED)\n",
    "    num_rows = 5\n",
    "    num_cols = 5\n",
    "    num_data = num_rows * num_cols\n",
    "    shuffled_index = random.sample(range(y_test.shape[0]), num_data)\n",
    "    X_sampled = tf.gather(X_test, shuffled_index)\n",
    "    y_sampled = tf.gather(y_test, shuffled_index)\n",
    "\n",
    "    y_pred_sampled = model.predict(X_sampled)\n",
    "    num_matches = 0\n",
    "\n",
    "    plt.figure(figsize=(18,12))\n",
    "    for i in range(num_data):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        pred = np.argmax(y_pred_sampled[i])\n",
    "        truth = np.argmax(y_sampled[i])\n",
    "        title = 'True: ' + str(truth) + '; Pred: ' + str(pred)\n",
    "        title_obj = plt.title(title, fontdict={'fontsize':16})\n",
    "        if pred == truth:\n",
    "            num_matches +=  1\n",
    "            plt.setp(title_obj, color='g')\n",
    "        else:\n",
    "            plt.setp(title_obj, color='r')\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(X_sampled[i].numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.show(block=block_plot)\n",
    "\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605f605-420d-418d-8025-656be34eb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN \n",
    "# Trt \n",
    "sys_config()\n",
    "\n",
    "\n",
    "(X_train_in, y_train_in), (X_test_in, y_test_in) = get_data()\n",
    "visualize_samples(X_test_in,y_test_in)\n",
    "((X_train, y_train), \n",
    " (X_validate, y_validate), \n",
    " (X_test, y_test)) = preprocess_data((X_train_in, y_train_in), \n",
    "                                     (X_test_in, y_test_in), \n",
    "                                     resize_to=(data_config.IMG_WIDTH, data_config.IMG_HEIGHT),\n",
    "                                     num_classes=data_config.NUM_CLASSES)\n",
    "model, training_results = train_model(train_set=(X_train, y_train), print_summary=True)\n",
    "train_loss = training_results.history['loss']\n",
    "train_acc = training_results.history['accuracy']\n",
    "valid_loss = training_results.history['val_loss']\n",
    "valid_acc = training_results.history['val_accuracy']\n",
    "plot_results([train_acc, valid_acc], ylabel='Accuracy', ylim=[0.5,1.0])\n",
    "test_set = (X_test, y_test)\n",
    "test_results = evaluate_model(model, *test_set)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf] *",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
